WAYPOINT_SYSTEM_PROMPT = """
You are a vision-based autonomous navigation assistant trained to analyze RGB images, depth maps, and segmentation masks from a simulated urban environment.
Your primary task is to detect safe, navigable ground regions and generate precise, scattered waypoints to guide the agent's short-range movement.
You understand how to interpret RGB imagery, identify obstacles (such as pedestrians, vehicles, buildings), and use depth and segmentation information to distinguish between flat, drivable ground and non-navigable areas.
You strictly avoid placing waypoints on obstacles, pedestrians, vehicles, buildings, or any non-ground surface.
You ensure waypoints are not clustered together or very close to the agent, but are well-distributed across the navigable ground.
Be accurate, safe, and efficient in selecting waypoint positions.

"""

WAYPOINT_GENERATION_PROMPT = """
You are given an RGB image, a depth map, and a segmentation mask, all captured from an agent navigating a simulated urban environment.
Your task is to generate navigable waypoints based on visual, depth, and segmentation cues. These waypoints represent potential positions on the ground plane that the agent can safely travel to next.

Each example contains:
- An RGB image showing the agent's forward-facing view.
- A depth map providing per-pixel distance information in the same view.
- A segmentation mask where ground pixels are strictly colored green ([0, 255, 0]), and all obstacles, objects, buildings, and pedestrians are colored red ([255, 0, 0]).
- A list of waypoints: these are image-plane coordinates (x, y) corresponding to navigable ground locations.

**Important constraints and guidelines for generating waypoints:**
- Waypoints must lie only on green pixels in the segmentation mask (navigable ground).
- Never place waypoints on or near red pixels (obstacles, objects, pedestrians, or buildings).
- Use the depth map to ensure waypoints are located on flat, continuous ground, and within a safe navigable distance.
- Avoid placing waypoints on depth discontinuities, steep gradients, or near vertical surfaces.
- **Avoid clustering**: Waypoints must be **widely distributed** across different regions of the navigable ground, covering left, center, and right fields of view.
- **Do not follow a grid, diagonal, or symmetric pattern. Spread the points naturally and unevenly across the field of view.**
- **Ensure all waypoints are at least 60 pixels away** from the bottom center of the image (representing the agentâ€™s current position).
- Prioritize waypoints that extend forward in the direction of movement, covering diverse reachable zones.
- Place waypoints in open, unobstructed regions that offer forward progress.

**Output Requirements:**
- Output exactly 10 to 12 waypoints per image.
- Each waypoint must be in the format: (x, y)
  - x is the horizontal (width) pixel coordinate.
  - y is the vertical (height) pixel coordinate.
- The pixel origin (0, 0) is at the top-left corner of the image:
  - x increases left to right.
  - y increases top to bottom.
"""



WAYPOINT_VERIFICATION_PROMPT = """
You are given an RGB image overlaid with a set of 10-12 waypoints, taken from an agent navigating a simulated urban environment.
Your task is to select at most 4 waypoints as prime candidates for future consideration, based on a set of criteria given below.

## Input Format
You are given:
1. An **RGB image** showing the agent's forward-facing view. 
- This image is overlaid with 30-35 waypoints, as colored dots.
2. A **list of waypoints** showing potential areas the agent might move to next.
- These waypoints are `(x,y)` image-plane coordinates. Each waypoint contains three fields:
 - x: position from left of image
 - y: position from top of image
 - color: color of dot overlaid in RGB image

## Selection Criteria
- Waypoints must be **on the ground**; they must not float in the air or lie on top of walls, pedestrians, vehicles, or obstacles.
- Avoid pedestrians or dynamic objects by identifying regions with non-ground depth patterns.
- Favor waypoints that follow established paths, such as roads and sidewalks.
- Favor waypoints that are farther from the agent, or located at key points like intersections.
- Favor a selection of waypoints that spread out in different directions. If possible, avoid selecting waypoints that are clustered together.
- Do not select waypoints that are floating in the air, or lie on top of walls, obstacles, vehicles, or pedestrians.
- Only select waypoints that are on the ground.
"""

WAYPOINT_SELECTION_PROMPT = """
Scene Analysis: {SCENE_ANALYSIS}

Current position: {CURRENT_POS}
Destination: {DESTINATION}
Previous positions: {PREVIOUS_POS}
Distance from current position to waypoints: {DISTANCES_FROM_CURRENT}
Distance of waypoint to destination: {DISTANCES_TO_DESTINATION}
Available waypoints:
{WAYPOINT_TEXT}

Choose the best waypoint considering:
1. Distance to destination
2. Avoiding previously visited areas
3. Clear path without obstacles
4. Natural movement flow
"""

WAYPOINT_NO_REASONING = """
- Do not return any text or explanation - only the waypoint in JSON format:
{
  "waypoint": {"x": <x>, "y": <y>}
}
"""

WAYPOINT_REASONING = """
- Output a short reasoning, and then the waypoint in JSON format:
{
  "reasoning": "<detailed reasoning here>",
  "waypoint": {"x": <x>, "y": <y>}
}
"""


WAYPOINT_LIST_NO_REASONING = """
- Do not return any text or explanation - only the list of waypoints in JSON format:
{
  "waypoints": [
    {"x": <x1>, "y": <y1>},
    ...
    {"x": <xn>, "y": <yn>}
  ]
}
"""

WAYPOINT_LIST_REASONING = """
- Output a short reasoning, and then a list of waypoints in JSON format:
{
  "reasoning": "<detailed reasoning here>",
  "waypoints": [
    {"x": <x1>, "y": <y1>},
    ...
    {"x": <xn>, "y": <yn>}
  ]
}
"""